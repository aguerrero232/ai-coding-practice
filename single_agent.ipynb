{"cells":[{"cell_type":"markdown","metadata":{},"source":["### Author: Ariel Guerrero\n","#### Single Agent Reinforcement Learning\n","Simple implementation of the single agent reinforcement learning algorithm."]},{"cell_type":"markdown","metadata":{},"source":["### imports"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import gym\n","import random\n","import numpy as np"]},{"cell_type":"markdown","metadata":{},"source":["### Functions for creating and describing the environment"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def new_env(env_name):\n","    \"\"\"\n","        description: Create a new environment.\n","    \"\"\"\n","    env = gym.make(env_name)\n","    return env\n","\n","\n","def env_attributes(env):\n","    \"\"\" \n","        description:    Prints Attributes of the environment \n","        @param env:      Gym environment\n","    \"\"\"\n","    print(\"observation space: \", env.observation_space)\n","    # number of actions\n","    if type(\n","            env.action_space) == gym.spaces.discrete.Discrete:\n","        print(\"action space: \", env.action_space)\n","    else:\n","        print(\"action range: \",\n","              env.action_space.low, env.action_space.high)\n"]},{"cell_type":"markdown","metadata":{},"source":["### Simple Agent class definition"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class Agent():\n","    \"\"\"\n","        description:    Agent with discrete or continuous action space\n","    \"\"\"\n","    def __init__(self, env):\n","        # I know its discrete but putting this here for future reference\n","        # is the agent discrete or continuous?\n","        self.is_discrete = type(\n","            env.action_space) == gym.spaces.discrete.Discrete\n","\n","        # if discrete, get the action size\n","        if self.is_discrete:\n","            self.action_size = env.action_space.n\n","        else:\n","            self.action_low = env.action_space.low\n","            self.action_high = env.action_space.high\n","            self.action_shape = env.action_space.shape\n","        env_attributes(env)\n","    def get_action(self, state):\n","        # if discrete, get the action\n","        if self.is_discrete:\n","            action = random.randrange(self.action_size)\n","        else:\n","            action = np.random.uniform(\n","                self.action_low,\n","                self.action_high,\n","                self.action_shape\n","            )\n","        return action"]},{"cell_type":"markdown","metadata":{},"source":["### different environments"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["env_name = 'MountainCarContinuous-v0'\n","# env_name = 'MountainCar-v0'\n","# env_name = 'Acrobot-v1'\n","# env_name = 'Pendulum-v1'"]},{"cell_type":"markdown","metadata":{},"source":["### create new environment"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["env = new_env(env_name)"]},{"cell_type":"markdown","metadata":{},"source":["### create a new agent"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["agent = Agent(env)"]},{"cell_type":"markdown","metadata":{},"source":["### fresh state"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["state = env.reset()"]},{"cell_type":"markdown","metadata":{},"source":["### Driver code"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for i_episode in range(200):\n","    action = agent.get_action(state)\n","    state, reward, done, info = env.step(action)\n","    env.render()"]},{"cell_type":"markdown","metadata":{},"source":["### closing the environment"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["env.close()"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":2}
